# Note 1 downside of Naive Bayes  

### 1: Word Independence
Naive Bayes assumes each word in a sentence is **independent** of the others.  
In real language, words often come in **patterns/collocations** (e.g., *sunny* and *hot*).  
This can make the model **overestimate or underestimate** how important certain words are.

---

### 2: Training Data Matches Real-World Distribution
Naive Bayes assumes the **class proportions** in training data match real life.  
But many datasets are **artificially balanced** (e.g., 50% positive / 50% negative).  
If real data is imbalanced, predictions can become **too optimistic or too pessimistic**.

---

### 3: Error Analysis for Misclassified Tweets  

When a sentence is classified wrong, check these common causes:

### Original tweet
> "My beloved grandmother :("

### After preprocessing (bad)
- remove punctuation/emoticons â†’ `"my beloved grandmother"`
- tokens â†’ `["beloved", "grandmother"]`

### What the model â€œseesâ€
- words look **warm/positive** â†’ predicts **Positive** âœ…
- but the real meaning is **sad** â†’ should be **Negative** âŒ

Fix idea: **donâ€™t blindly delete emoticons** (keep `:(`, `:)`, `ğŸ˜­`, etc.)

---

### 4: Even worse: removing **not** flips sentiment

### Original tweet
> "This is not good because your attitude is not even close to being nice."

### After preprocessing (very bad)
- remove stopwords/neutral words (wrong) â†’ `"good attitude close nice"`
- tokens â†’ `["good", "attitude", "close", "nice"]`

### What the model â€œseesâ€
- many **positive words** â†’ predicts **Positive** âœ…  
- but the real sentiment is **Negative** âŒ

Fix idea: **never remove negations** like `not`, `never`, `no`

---

### 5: Word order matters 

### Tweet A (Positive)
> "Iâ€™m happy because I did not go."

Meaning: *Iâ€™m happy (reason: I didnâ€™t go)* âœ…

### Tweet B (Negative)
> "Iâ€™m not happy because I did not go."

Meaning: *Iâ€™m unhappy (reason: I didnâ€™t go)* âŒ

### Why Naive Bayes fails
Both contain similar keywords:
- `{happy, not, go, because}`  
But **â€œnotâ€ attaches to different parts**, changing meaning.

Fix idea: use **bigrams / n-grams** or models that learn word order

---
### 6: Sarcasm / irony 
### Original tweet (actually Positive)
> "This is a ridiculously powerful movie. The plot was gripping and I cried until the ending."

### What Naive Bayes might latch onto
- negative-looking words: `["ridiculously", "cried"]`
- ignores the â€œwow this is amazingâ€ tone

So it may predict **Negative** âœ…  
but real label is **Positive** âŒ

Fix idea: sarcasm is hard â€” use better features (context, embeddings) + more data

---
